[10/09/2022 10:56:39 INFO]: 
_________________________________________________

[10/09/2022 10:56:39 INFO]: train_model.py main() running.
[10/09/2022 10:56:39 INFO]: problem:
  hyp:
    alpha: 1
    clip: 1
    epochs: 150
    lr: 0.001
    lr_decay: step
    lr_factor: 0.1
    lr_schedule:
    - 60
    - 100
    lr_throttle: false
    optimizer: adam
    save_period: -1
    test_batch_size: 500
    test_mode: default
    train_batch_size: 100
    train_mode: progressive
    val_period: 20
    warmup_period: 10
  model:
    model: feedforward_net_recall_1d
    model_path: null
    width: 400
    max_iters: 30
    test_iterations:
      low: 30
      high: 30
  name: prefix_sums
  test_data: 512
  train_data: 32
train_log: train_log
name: prefix_sums_ablation
run_id: introrse-Shiloh

2022-10-09 10:56:39.799749: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-10-09 10:56:39.924837: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2022-10-09 10:56:40.954450: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /local/java/cuda-11.6.0/lib64/:/local/java/cudnn-linux-x86_64-8.5.0.96_cuda11-archive/lib64/
2022-10-09 10:56:40.954508: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /local/java/cuda-11.6.0/lib64/:/local/java/cudnn-linux-x86_64-8.5.0.96_cuda11-archive/lib64/
2022-10-09 10:56:40.954515: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
Files already downloaded and verified
Loading data with 32 bits.
Files already downloaded and verified
Loading data with 512 bits.
[10/09/2022 10:56:44 INFO]: This feedforward_net_recall_1d has 58.804 million parameters.
[10/09/2022 10:56:44 INFO]: Training will start at epoch 0.
[10/09/2022 10:56:44 INFO]: ==> Starting training for 150 epochs...
  0%|          | 0/80 [00:00<?, ?it/s]  1%|▏         | 1/80 [00:00<01:14,  1.06it/s]  2%|▎         | 2/80 [00:01<00:57,  1.35it/s]  4%|▍         | 3/80 [00:02<00:47,  1.61it/s]                                              Error executing job with overrides: ['problem.hyp.alpha=1', 'problem/model=ff_net_recall_1d', 'problem=prefix_sums', 'name=prefix_sums_ablation', '+run_id=introrse-Shiloh']
Traceback (most recent call last):
  File "/dcs/20/u2004277/Documents/deep-thinking/train_model.py", line 82, in main
    loss, acc = dt.train(net, loaders, cfg.problem.hyp.train_mode, train_setup, device)
  File "/dcs/20/u2004277/Documents/deep-thinking/deepthinking/utils/training.py", line 61, in train
    train_loss, acc = train_progressive(net, loaders, train_setup, device)
  File "/dcs/20/u2004277/Documents/deep-thinking/deepthinking/utils/training.py", line 94, in train_progressive
    outputs_max_iters, _ = net(inputs, iters_to_do=max_iters)
  File "/dcs/20/u2004277/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/dcs/20/u2004277/.local/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py", line 166, in forward
    return self.module(*inputs[0], **kwargs[0])
  File "/dcs/20/u2004277/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/dcs/20/u2004277/Documents/deep-thinking/deepthinking/models/feedforward_net_1d.py", line 78, in forward
    out = self.head(interim_thought)
  File "/dcs/20/u2004277/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/dcs/20/u2004277/.local/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/dcs/20/u2004277/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/dcs/20/u2004277/.local/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 98, in forward
    return F.relu(input, inplace=self.inplace)
  File "/dcs/20/u2004277/.local/lib/python3.9/site-packages/torch/nn/functional.py", line 1299, in relu
    result = torch.relu(input)
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 3.82 GiB total capacity; 2.60 GiB already allocated; 17.62 MiB free; 2.77 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
